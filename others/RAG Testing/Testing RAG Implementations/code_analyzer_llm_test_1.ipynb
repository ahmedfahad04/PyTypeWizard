{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A over the Code Base to Understand How it Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fahad/Documents/Projects/SPL Excessories/SPL3/others/Test v2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"pytagfix-master\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Project (Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(repo_path,\n",
    "                                       glob = \"**/*\",\n",
    "                                       suffixes=[\".py\"],\n",
    "                                       parser = LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'pytagfix-master/test.py', 'language': <Language.PYTHON: 'python'>}, page_content='# custom type\\nclass Student:\\n    def __init__(self, name: str, age: int, school: str):\\n        self.name = name\\n        self.age = age\\n        self.school = school\\n\\n\\ndef print_student_details(student: Student) -> None:\\n    print(student.name, student.age)\\n\\n\\n# newtype\\nfrom typing import NewType\\n\\nStudentID = NewType(\"StudentID\", int)\\nCourseID = NewType(\"CourseID\", int)\\n\\n\\ndef get_student(student_id: StudentID) -> None:\\n    pass\\n\\n\\ndef enroll_in_course(student_id: StudentID, course_id: CourseID) -> None:\\n    pass\\n\\n\\n# generics\\nfrom typing import List, TypeVar\\n\\nT = TypeVar(\"T\")\\n\\n\\ndef first_element(lst: List[T]) -> T:\\n    return lst[0]\\n\\n\\nfrom typing import Generic, TypeVar\\n\\nT = TypeVar(\"T\")\\n\\n\\nclass Box(Generic[T]):\\n    def __init__(self, value: T):\\n        self.value = value\\n\\n    def get(self) -> T:\\n        return self.value\\n\\n\\ndef calculate_taxes(incomes: list[float], tax_rate: float) -> list[float]:\\n    return [income * tax_rate for income in incomes]\\n\\n\\nincomes = [50000.0, 60000.0, \"75000.0\"]  \\ntax_rate = 0.2\\ntaxes = calculate_taxes(incomes, tax_rate)  \\n\\n\\n# # Option 1: Fix the data to ensure all values are float\\n# def calculate_taxes(incomes: list[float], tax_rate: float) -> list[float]:\\n#     return [income * tax_rate for income in incomes]\\n\\n\\n# # After correction, the string \"75000.0\" is converted to a float\\n# incomes = [50000.0, 60000.0, 75000.0]\\n# tax_rate = 0.2\\n# taxes = calculate_taxes(incomes, tax_rate)  # Now it works correctly.\\n\\n\\n# # Option 2: Update the type hint to handle possible string-float mismatches from parsing\\n# def calculate_taxes(incomes: list[float | str], tax_rate: float) -> list[float]:\\n#     return [float(income) * tax_rate for income in incomes]\\n\\n\\n# # PyTypeWizard allows for string numbers and converts them automatically\\n# incomes = [50000.0, 60000.0, \"75000.0\"]  # Strings are handled and converted to float\\n# tax_rate = 0.2\\n# taxes = calculate_taxes(incomes, tax_rate)\\n# print(\"NEW TAX: \", taxes)\\n'),\n",
       " Document(metadata={'source': 'pytagfix-master/prettytitle.py', 'language': <Language.PYTHON: 'python'>}, page_content='import re\\n\\nENG_DONT_CAP = (\\n    # Don\\'t capitalize articles (a, an, the),\\n    # unless the article is part of an artist\\'s name.\\n    \"a\",\\n    \"an\",\\n    \"the\",\\n    # Don\\'t capitalize coordinating conjunctions:\\n    \"and\",\\n    \"but\",\\n    \"or\",\\n    \"nor\",\\n    \"for\",\\n    \"yet\",\\n    \"so\",\\n    # Don\\'t capitalize these prepositions:\\n    \"as\",\\n    \"at\",\\n    \"by\",\\n    \"for\",\\n    \"in\",\\n    \"of\",\\n    \"on\",\\n    \"to\",\\n    # The word versus (and its abbreviated form vs. or v.) is commonly left\\n    # in lower case, despite its being a preposition of more than 3 characters.\\n    \"vs\",\\n    \"versus\",  # NOTE: not adding \\'v\\' here because of roman number V\\n    # The word Et cetera (and its abbreviated form etc.) is also commonly left\\n    # in lower case when used to represent the phrase and so on or and so forth.\\n    \"etc\",\\n    # Capitalize contractions and slang consistent with the rules above\\n    # to the extent that such clearly apply.\\n    # For example, do not capitalize o\\' for of, or n\\' for and, etc.\\n    \"o\\'\",\\n    \"n\\'\",\\n    # Some additional words used as slang...\\n    \"ov\",\\n    \"ye\",\\n)\\n# All prepositions with four or more letters\\n# such as into, from, with, upon, etc. should be capitalized.\\n\\nRUSCAP_RE = (\\n    \"—Å–∞—Ç–∞–Ω([–∞—ã–µ—É]|–æ–π)?\",\\n    \"–¥—å—è–≤–æ–ª([–∞—É–µ]|–æ–º)?\",\\n    \"—Ö—Ä–∏—Å—Ç(–æ—Å)?([–∞—É–µ]|–æ–º)?\",\\n    \"–∏–∏—Å—É—Å([–∞—É–µ]|–æ–º)?\",\\n    \"—Ç—å–º([–∞—ã–µ—É]|–æ–π|–æ—é)\",\\n    \"—Ö–∞–æ—Å([–∞–µ—É]|–æ–º)?\",\\n    \"–ø—É—Å—Ç–æ—Ç([–∞—ã—É]|–æ–π)\",\\n)\\n\\nCYRILLIC_LETTERS = \"–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è\"\\nCONSONANTS = \"BCDFGHJKLMNPQRSTVWXZ\" + \"–ë–í–ñ–ó–ô–ö–õ–ú–ù–ü–†–°–¢–§–•–¶–ß–®–©\"\\nPLUSES = \"–™–¨-\\'`\"\\n\\n\\ndef pw_eng(w: str, newsent: bool = False) -> str:\\n    # Capitalize every part of words with \\'-\\' or \\'/\\'\\n    for symbol in \"-/\":\\n        if symbol in w:\\n            return symbol.join(pw_eng(x, newsent=True) for x in w.split(symbol))\\n    if not newsent and (w.lower() in ENG_DONT_CAP):\\n        return w.lower()\\n    return w.capitalize()\\n\\n\\ndef pw_rus(w: str, newsent: bool = False) -> str:\\n    if newsent:\\n        return w.capitalize()\\n    elif any(re.fullmatch(x, w.lower()) for x in RUSCAP_RE):\\n        return w.capitalize()\\n    else:\\n        return w.lower()\\n\\n\\ndef pretty_word(s: str, newsent: bool = False, lang: str = \"eng\") -> str:\\n    \"\"\"Return right title-cased word based on lang rules\"\"\"\\n    if not s:\\n        return \"\"\\n    if s[-1] in \".!?;:)]‚Ä¶\":\\n        return pretty_word(s[:-1], newsent=newsent, lang=lang) + s[-1]\\n    if s[0] in \"([\\'\\\\\"‚Ä¶\":\\n        return s[0] + pretty_word(s[1:], newsent=newsent, lang=lang)\\n    if s.startswith(\"...\"):\\n        return \"...\" + pretty_word(s[3:], newsent=newsent, lang=lang)\\n\\n    # Don\\'t touch abbreviatures and roman numbers\\n    if (s.isupper() and (s.strip(\"().-IVXLCDM\") == \"\")) or (s.count(\".\") > 0):\\n        return s\\n\\n    # Don\\'t touch words with only consonant letters,\\n    # it\\'s most likely not a regular word.\\n    if (len(s) > 1) and (s.upper().strip(CONSONANTS + PLUSES) == \"\"):\\n        return s\\n\\n    if lang == \"eng\":\\n        return pw_eng(s, newsent)\\n    elif lang == \"rus\":\\n        return pw_rus(s, newsent)\\n\\n\\n# NOTE: For the `return` error above its basically not a type error rather here we need an else condition that return\\n# any valid string. For that cases, we need to integrate LLM support to handle such cases where we\\'ll compare the solution\\n# and reason with llm to get the perfect result.\\n\\n\\ndef pretty_string(s: str, lang: str = None) -> str:  ##! RESOLVE this error\\n    \"\"\"Return correctly titled string\"\"\"\\n    newwords: list = []\\n    newsent: bool = True\\n\\n    # Lang detect. FIXME: Primitive for now\\n    if lang is None:\\n        if any(x in s for x in CYRILLIC_LETTERS):\\n            lang = \"rus\"\\n        else:\\n            lang = \"eng\"\\n\\n    for w in s.split():\\n        word = pretty_word(w, newsent, lang=lang)\\n        newwords.append(word)\\n        newsent = (word[-1] in \".!?;:)]‚Ä¶\") or (word in (\"-\", \"/\", \"‚Äî\"))\\n\\n    if lang == \"eng\":\\n        # also capitalize the very last word\\n        newwords[-1] = pretty_word(newwords[-1], True, lang=\"eng\")\\n\\n    if newwords[-1] == \"Cover)\":\\n        newwords[-1] = \"cover)\"\\n    if newwords[-1] == \"Cover]\":\\n        newwords[-1] = \"cover]\"\\n    return \" \".join(newwords)\\n'),\n",
       " Document(metadata={'source': 'pytagfix-master/pytagfix.py', 'language': <Language.PYTHON: 'python'>}, page_content='#!/usr/bin/python\\n\\nimport os\\nimport sys\\nimport typing\\n\\nimport taglib\\n\\nfrom prettytitle import pretty_string\\n\\n\\ndef process_dir(srcdir: str):\\n    mf = []\\n    for dirpath, dirs, files in os.walk(srcdir, topdown=False):\\n        for name in sorted(files):\\n            try:\\n                ff = taglib.File(os.path.join(os.path.abspath(dirpath), name))\\n            except:\\n                print(\"SKIPPING not music file: {0}\".format(name))\\n            else:\\n                mf.append(ff)\\n    process_music_files(mf)\\n\\n\\ndef input_yes(s: str):\\n    ans: str = input(\"{} [y/N]\".format(s))\\n    if ans and (ans in \"yY\"):\\n        return True\\n    return False\\n\\n\\ndef get_album_artist(artist_list: list):\\n    print(\"More then one artist found\")\\n    if len(artist_list) < 5:\\n        if input_yes(\"Is it Split\"):\\n            return \" & \".join(artist_list)\\n    else:\\n        if input_yes(\"Is it VA\"):\\n            return \"VA\"\\n    return None\\n\\n\\ndef get_common_data(files: list):\\n    newdata = {\"ARTIST\": [], \"ALBUM\": [], \"DATE\": [], \"GENRE\": []}\\n    for tagname in sorted(newdata.keys()):\\n        for f in files:\\n            if tagname in f.tags:\\n                d = f.tags[tagname]\\n                d = pretty_string(d[0])\\n                if d and d not in newdata[tagname]:\\n                    newdata[tagname].append(d)\\n        if not newdata[tagname]:\\n            newdata[tagname] = [input(\"No {0} found. Enter {0}: \".format(tagname))]\\n    if len(newdata[\"ARTIST\"]) > 1:\\n        albumartist = get_album_artist(newdata[\"ARTIST\"])\\n        if albumartist is None:\\n            print(\"\\\\nArtists are: \\\\n    \" + \"\\\\n    \".join(newdata[\"ARTIST\"]))\\n            newdata[\"ARTIST\"] = [input(\"Enter Artist: \")]\\n        else:\\n            newdata[\"ALBUMARTIST\"] = [albumartist]\\n    for tagname in (\"ALBUM\", \"DATE\"):\\n        if len(newdata[tagname]) > 1:\\n            print(\"More then one {0} found:\".format(tagname))\\n            print(\"    \" + \"\\\\n    \".join(newdata[tagname]))\\n            newdata[tagname] = [input(\"Enter {0}: \".format(tagname))]\\n    if len(newdata[\"DATE\"][0]) != 4:\\n        print(\"Date doesn\\'t look like a year number: \" + newdata[\"DATE\"][0])\\n        newdate = input(\\n            \"Enter date or press enter to use {0}:\".format(newdata[\"DATE\"][0])\\n        )\\n        if newdate:\\n            newdata[\"DATE\"] = [newdate]\\n    return newdata\\n\\n\\ndef process_music_files(files: list):\\n    newdata = get_common_data(files)\\n    print(\"For ALL songs tags will be set to:\")\\n    for k in sorted(newdata):\\n        if len(newdata[k]) == 1:\\n            print(\"{0:>12}: {1}\".format(k, newdata[k][0]))\\n\\n    newfiles = []\\n    for f in files:\\n        print(\"F: \", type(f))\\n        f = edit_tags_common(f, newdata)\\n        f = edit_tags1(f)\\n        if str(f.path).lower().endswith(\"mp3\"):\\n            if \"TOTALTRACKS\" in f.tags:\\n                del f.tags[\"TOTALTRACKS\"]\\n            if \"/\" not in f.tags[\"TRACKNUMBER\"][0]:\\n                f.tags[\"TRACKNUMBER\"][0] = \"{0}/{1:02d}\".format(\\n                    f.tags[\"TRACKNUMBER\"][0], len(files)\\n                )\\n        else:\\n            f.tags[\"TOTALTRACKS\"] = [\"{0:02d}\".format(len(files))]\\n\\n        newfiles.append(f)\\n\\n    for f in newfiles:\\n        f.save()\\n\\n    # Print \\'Artist - YYYY - Album\\'\\n    print(\\n        \" - \".join(\\n            (\\n                newdata.get(\"ALBUMARTIST\", newdata[\"ARTIST\"])[0],\\n                newdata[\"DATE\"][0],\\n                newdata[\"ALBUM\"][0],\\n            )\\n        )\\n    )\\n\\n\\ndef edit_tags_common(f, common: dict):\\n    f.tags[\"ALBUM\"] = common[\"ALBUM\"]\\n    f.tags[\"DATE\"] = common[\"DATE\"]\\n\\n    if \"ALBUMARTIST\" in common:\\n        f.tags[\"ALBUMARTIST\"] = common[\"ALBUMARTIST\"]\\n        f.tags[\"ARTIST\"] = [pretty_string(f.tags[\"ARTIST\"][0])]\\n    else:\\n        if \"ALBUMARTIST\" in f.tags:\\n            del f.tags[\"ALBUMARTIST\"]\\n        f.tags[\"ARTIST\"] = common[\"ARTIST\"]\\n\\n    if \"GENRE\" in f.tags:\\n        f.tags[\"GENRE\"] = [pretty_string(f.tags[\"GENRE\"][0])]\\n    else:\\n        f.tags[\"GENRE\"] = common[\"GENRE\"]\\n    return f\\n\\n\\ndef edit_tags1(f):\\n    if \"TRACKNUMBER\" in f.tags:\\n        f.tags[\"TRACKNUMBER\"] = [f.tags[\"TRACKNUMBER\"][0].zfill(2)]\\n    else:\\n        filename = os.path.basename(f.path)\\n        if filename[:2].isdigit():\\n            f.tags[\"TRACKNUMBER\"] = [filename[:2]]\\n        else:\\n            f.tags[\"TRACKNUMBER\"] = [\\n                input(\"Enter TRACKNUMBER for \\'{0}\\': \".format(filename))\\n            ]\\n\\n    # Delete dummy comments\\n    if \"COMMENT\" in f.tags and f.tags[\"COMMENT\"][0].lower().startswith(\"track\"):\\n        if f.tags[\"COMMENT\"][0].split(num=1)[1].isalnum():\\n            del f.tags[\"COMMENT\"]\\n\\n    if \"TITLE\" in f.tags:\\n        f.tags[\"TITLE\"] = [pretty_string(f.tags[\"TITLE\"][0])]\\n    else:\\n        f.tags[\"TITLE\"] = [\"[untitled]\"]\\n\\n    # Strip leading tracknumber from track title\\n    if f.tags[\"TITLE\"][0].startswith(f.tags[\"TRACKNUMBER\"][0]):\\n        if f.tags[\"TITLE\"][0][2:4] in (\". \", \" -\", \"- \"):\\n            f.tags[\"TITLE\"][0] = f.tags[\"TITLE\"][0][4:].lstrip()\\n\\n    todel = (\"band\", \"performer\", \"album artist\", \"tracktotal\")\\n    for prop in todel + tuple(x.upper for x in todel):\\n        if prop in f.tags:\\n            print(\"deleting \\'{0}\\' from \\'{1}\\'\".format(prop, os.path.basename(f.path)))\\n            del f.tags[prop]\\n    return f\\n\\n\\ndef main():\\n    if len(sys.argv) < 2:\\n        print(\"You should specify an album directory\")\\n        return 1\\n\\n    for d in sys.argv[1:]:\\n        print(\"\\\\nProcessing \\'{0}\\'\".format(d))\\n        process_dir(d)\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n'),\n",
       " Document(metadata={'source': 'pytagfix-master/album_creator.py', 'language': <Language.PYTHON: 'python'>}, page_content='import os\\nimport shutil\\n\\nimport mutagen.mp3\\n\\n\\ndef create_sample_album():\\n    album_path = os.path.join(\\n        \"Music_Album\", \"Python_Auto_Music_Hub\", \"2023_Russel_Viper\"\\n    )\\n    os.makedirs(album_path, exist_ok=True)\\n\\n    source_mp3 = (\\n        \"boop.mp3\"  # Make sure this file exists in the same directory as the script\\n    )\\n\\n    for i in range(1, 11):\\n        filename = f\"{i:02d} - Track {i}.mp3\"\\n        filepath = os.path.join(album_path, filename)\\n\\n        # Copy the existing MP3 file\\n        shutil.copy(source_mp3, filepath)\\n\\n        # Add basic tags\\n        audio = mutagen.mp3.MP3(filepath)\\n        audio[\"TPE1\"] = mutagen.id3.TPE1(encoding=3, text=\"Python Auto Music Hub\")\\n        audio[\"TALB\"] = mutagen.id3.TALB(encoding=3, text=\"Russel Viper\")\\n        audio[\"TIT2\"] = mutagen.id3.TIT2(encoding=3, text=f\"Track {i}\")\\n        audio[\"TDRC\"] = mutagen.id3.TDRC(encoding=3, text=\"2023\")\\n        audio[\"TRCK\"] = mutagen.id3.TRCK(encoding=3, text=str(i))\\n        audio.save()\\n\\n    print(f\"Sample album created at: {album_path}\")\\n\\n\\nif __name__ == \"__main__\":\\n    create_sample_album()\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1946"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'pytagfix-master/test.py', 'language': <Language.PYTHON: 'python'>}, page_content='# custom type\\nclass Student:\\n    def __init__(self, name: str, age: int, school: str):\\n        self.name = name\\n        self.age = age\\n        self.school = school\\n\\n\\ndef print_student_details(student: Student) -> None:\\n    print(student.name, student.age)\\n\\n\\n# newtype\\nfrom typing import NewType\\n\\nStudentID = NewType(\"StudentID\", int)\\nCourseID = NewType(\"CourseID\", int)\\n\\n\\ndef get_student(student_id: StudentID) -> None:\\n    pass\\n\\n\\ndef enroll_in_course(student_id: StudentID, course_id: CourseID) -> None:\\n    pass\\n\\n\\n# generics\\nfrom typing import List, TypeVar\\n\\nT = TypeVar(\"T\")\\n\\n\\ndef first_element(lst: List[T]) -> T:\\n    return lst[0]\\n\\n\\nfrom typing import Generic, TypeVar\\n\\nT = TypeVar(\"T\")\\n\\n\\nclass Box(Generic[T]):\\n    def __init__(self, value: T):\\n        self.value = value\\n\\n    def get(self) -> T:\\n        return self.value\\n\\n\\ndef calculate_taxes(incomes: list[float], tax_rate: float) -> list[float]:\\n    return [income * tax_rate for income in incomes]\\n\\n\\nincomes = [50000.0, 60000.0, \"75000.0\"]  \\ntax_rate = 0.2\\ntaxes = calculate_taxes(incomes, tax_rate)  \\n\\n\\n# # Option 1: Fix the data to ensure all values are float\\n# def calculate_taxes(incomes: list[float], tax_rate: float) -> list[float]:\\n#     return [income * tax_rate for income in incomes]\\n\\n\\n# # After correction, the string \"75000.0\" is converted to a float\\n# incomes = [50000.0, 60000.0, 75000.0]\\n# tax_rate = 0.2\\n# taxes = calculate_taxes(incomes, tax_rate)  # Now it works correctly.\\n\\n\\n# # Option 2: Update the type hint to handle possible string-float mismatches from parsing\\n# def calculate_taxes(incomes: list[float | str], tax_rate: float) -> list[float]:\\n#     return [float(income) * tax_rate for income in incomes]\\n\\n\\n# # PyTypeWizard allows for string numbers and converts them automatically\\n# incomes = [50000.0, 60000.0, \"75000.0\"]  # Strings are handled and converted to float\\n# tax_rate = 0.2\\n# taxes = calculate_taxes(incomes, tax_rate)\\n# print(\"NEW TAX: \", taxes)\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Document to store in Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_splitter = RecursiveCharacterTextSplitter.from_language(language = Language.PYTHON,\n",
    "                                                             chunk_size = 500,\n",
    "                                                             chunk_overlap = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = documents_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "# Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GEMINI_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahad/miniconda3/envs/ptenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# embeddings=OpenAIEmbeddings(disallowed_special=())\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7078dc1aeed0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Vector DB & Create QA Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Path 1Ô∏è‚É£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for answering query realted to coding. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question \"\n",
    "    \"If you don't know the answer, say that you don't know.\"\n",
    "    \"Answer queries to the point and relevant format\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0.5, max_tokens=4018, google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "question_answering_chain=create_stuff_documents_chain(llm, chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"which one is the main python script in pytagfix-master?\\n answer in one line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main Python script in pytagfix-master is not shown in the provided code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message1= rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})\n",
    "print(message1[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Best Implementation üîΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", output_key='answer', return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm, \n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 8}), \n",
    "    memory=memory, \n",
    "    return_source_documents=True, \n",
    "    output_key=\"answer\"  # Specify the output key to resolve ambiguity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = ''' \n",
    "what are the python scripts in this project? mention the names.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code snippet doesn't define any complete Python scripts. It shows parts of functions and other code fragments, but there's no indication of a top-level script name or how these pieces fit together into a complete program.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = qa(question)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_code = 'def walk_metas(app):\\n # Iterates from deepest to shallowest meta-apps meta_list = [app]  # shallowest to deepest meta = app while (meta := meta._meta) and meta.default_command:'\n",
    " \n",
    "question = '''\n",
    "This is an object containing pyre error message and a warning line\n",
    "{\n",
    "    message = 'In call `ResolvedCommand.__init__`, for 4th positional argument, expected `Optional[Group]` but got `Union[None, Group, str]`.'\n",
    "    rule_id = 'Incompatible parameter type [6]'\n",
    "    source_code = 'def walk_metas(app):\\n # Iterates from deepest to shallowest meta-apps meta_list = [app]  # shallowest to deepest meta = app while (meta := meta._meta) and meta.default_command:',\n",
    "    warning_line = 'apps[-1].group_parameters,'\n",
    "}\n",
    "\n",
    "Now do as follows:\n",
    "1. find the method where the `warning_line` is present\n",
    "2. inspect error for that method\n",
    "3. provide ONLY the correct code snippets\n",
    "4. short explanation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
